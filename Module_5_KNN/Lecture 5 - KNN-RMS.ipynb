{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaTzHRkCbf-X"
   },
   "source": [
    "To open notebook in Colab please click below:\n",
    "<a href=\"https://colab.research.google.com/github/bwolfson2/dsclass2022/blob/main/Module_5_KNN/Lecture%205%20-%20KNN-RMS.ipynb\" target=\"_parent\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" /> </a>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Palatino; font-size: 40px; color: purple\">\n",
    "             k-Nearest Neigbors (KNN)\n",
    "</span>\n",
    "\n",
    "\n",
    "Spring 2022 - Instructors: Roger Stein and Ben Wolfson -\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o27tIlWJbf-f",
    "outputId": "37707040-3cc1-4314-e7a6-73bc8950d164",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If opening in colab run this cell\n",
    "#!git clone https://github.com/bwolfson2/dsclass2022\n",
    "#%cd dsclass2022/Module_5_KNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "\n",
    "    <STYLE type=\"text/css\">\n",
    "       H1 {font-family: Palatino; font-size: 30px; color: purple}\n",
    "    </STYLE>\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN algorithms sort all known observations by some measure of “distance” from the observation whose unknown target value we wish to predict.  Distance is calculated using only features (independent variables), _excluding the target_.  Typically the distance is measured as the Euclidian distance (though others are sometimes used).\n",
    "\n",
    "To make a prediction, we: \n",
    "1. sort all of the observations by distance from the unknown observation;\n",
    "1. create a “neighborhood” of size k (k is a hyper parameter) that includes the k nearest neighbors;\n",
    "1. aggregate the target values for all of the neighbors (using mean, majority, etc.); and \n",
    "1. return aggregated value as the prediction.\n",
    "\n",
    "Let's see how we would implement KNN from scratch, using only `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8u8aHhWbf-l"
   },
   "source": [
    "# Set-up and housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8u8aHhWbf-l"
   },
   "source": [
    "## Some general imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuSW0WuBbf-l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some helper functions that we will use later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building KNN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ9Nt8jgbf-x"
   },
   "source": [
    "### dist_euclidian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "Image(url=\"./images/euclid_dist.png\", width=350, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d(A,B)=\\sqrt{\\Delta_1^2~+~\\Delta_2^2 +\\dots +\\Delta_m^2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "id": "dYNk3OSgbf-x",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_euclidian(x1, x2):\n",
    "    m = len(x1)\n",
    "    sqr_dists     = [(x1[i]-x2[i])**2 for i in range(m)] \n",
    "    sum_sqr_dists = np.sum(sqr_dists)\n",
    "    d             = np.sqrt(sum_sqr_dists)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc_distances_for_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_distances_for_all(x_new,X, dist_metric):\n",
    "    n     = X.shape[0]\n",
    "    dists = [dist_metric(x_new,X[i,:]) for i in range(n)]\n",
    "    return(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "#\n",
    "# Load the Sklearn IRIS dataset\n",
    "#\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "#\n",
    "# Create train and test split\n",
    "#\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "m = X_train.shape[1]\n",
    "x_test  = X_test[0,:]      # get first test record to demo distance calculations\n",
    "x_train = X_train[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difs    = x_train  - x_test\n",
    "difs_sq = [np.round(difs[i]**2,1) for i in range(m)]\n",
    "\n",
    "print(\"x_train:         \", x_train)\n",
    "print(\"x_test:          \", x_test)\n",
    "print(\"differences:     \", difs)\n",
    "print(\"difs^2:          \", np.round(difs_sq,1))\n",
    "print(\"sum(difs^2)      \", np.sum(difs_sq))\n",
    "print(\"sqrt(sum(difs^2))\",np.round(np.sqrt(np.sum(difs_sq)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dist_euclidian(x_train, x_test)\n",
    "print (\"dist_euclidian(x_train, x_test): \", np.round(d,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good.  `dist_euclidian` produces the same results as our hand calculation.  Now let's calculate the distance of our \"unknown\" observation from all of our training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc distances from all points in test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = calc_distances_for_all(x_test,X_train, dist_euclidian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(ds[0:5],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the distance of the \"unknown\" data point, each point in the training data, we can find the $k$ nearest neighbors to the \"unknown\" point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find $k$ nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(ds)\n",
    "\n",
    "print(\"Sorted index of `X_train`  from shortest to longest distance:\\n\")\n",
    "print(sorted_idx)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"`X_train` distances sorted from shortest to longest:\\n\")\n",
    "print([np.round(ds[i],2) for i in sorted_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction (finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from collections import Counter\n",
    "\n",
    "k = 32\n",
    "idx = sorted_idx[0:k]\n",
    "Y_neighbors = Y_train[idx]\n",
    "print(\"y neighbors: \", Y_neighbors)\n",
    "print(\"\\nThe majority class in the neighborhood is: \", mode(Y_neighbors))\n",
    "\n",
    "counts = Counter(Y_neighbors)\n",
    "class_labels      = [ l  for l in counts.keys()]\n",
    "class_frequencies = [ v/k for v in counts.values()]\n",
    "cf = pd.DataFrame({\"class\": class_labels,\"freq\": np.round(class_frequencies,3)})\n",
    "print(\"\\n\", cf)\n",
    "\n",
    "true_y = Y_test[0]\n",
    "print(\"\\n** True class ** : \", true_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we understand how the mechanics work, let's try to do the same thing, at scale, using `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out the `iris` dataset using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IRIS dataset\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops...When we fit the model by hand, we forgot to look at the data first!\n",
    "\n",
    "Let's remedy that mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 2, 2\n",
    "variables  = ['x1',     'x2',   'x3', 'x4']\n",
    "colors     = ['purple',  'gray',        'green', 'lightblue']\n",
    "nvars      = len(variables)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(7*cols, 7*rows))\n",
    "axs      = axs.flatten()\n",
    "params   = {'axes.titlesize':'28', 'xtick.labelsize':'20', 'ytick.labelsize':'20'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "for i in range(len(variables)):\n",
    "    v = variables[i]\n",
    "    axs[i].hist(X_train[:,i], color = colors[i])\n",
    "    axs[i].set_title(v)\n",
    "    if i > 0:\n",
    "        axs[i].sharex(axs[0])   # keep x axis limits the same for easy comp. \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the scales of the variables have different magnitudes...\n",
    "\n",
    "This means that they will make uneven contributions to the distance function since a difference of, say, 1 for a variable that ranges from 0 to 100 probably shouldn't be as 'different' as a difference of 1 for a variable that ranges from 0 to 2.\n",
    "\n",
    "We can fix this by rescaling the data before we fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Scale the data so each variable has mean  zero and standard deviation 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often where the modelling can go wrong.  Some Data Scientists accidentally peek into the future when they proprocess the data, because the use the _test_ data to cancluate the preproccing parameters when, by reapplying the _entire_ preprocessing step on the test data, when they should only apply the _transformation_ section, using the parameters that were already estimated from the training data.\n",
    "\n",
    "Let's take a look at the right way and wrong way to rescale data for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Variable scaling\n",
    "\n",
    "std_train = StandardScaler()\n",
    "std_train.fit(X_train)\n",
    "X_train_std    = std_train.transform(X_train)\n",
    "    \n",
    "              \n",
    "std_test_ng   = StandardScaler()                # This is wrong...!\n",
    "std_test_ng.fit(X_test)                         # wrong...!\n",
    "X_test_std_ng = std_test_ng.transform(X_test)   # wrong...!\n",
    "\n",
    "X_test_std    = std_train.transform(X_test)     # This is right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is `std_test_ng` wrong?\n",
    "\n",
    "Let's look at some details about each StandardScalar object we fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PARAMETERS OF SCALERS\")\n",
    "print(\"========== == =======\\n\")\n",
    "\n",
    "mu    = std_train.mean_\n",
    "sigma = np.sqrt(std_train.var_)\n",
    "print(\"means, sds from std_train   :\\n    mean=\", np.round(mu,2),\"\\n    sd=  \",  np.round(sigma,2))  \n",
    "print(\"\\n\")\n",
    "mu    = std_test_ng.mean_\n",
    "sigma = np.sqrt(std_test_ng.var_)\n",
    "print(\"means, sds from std_test    :\\n    mean=\", np.round(mu,2),\"\\n    sd=  \",  np.round(sigma,2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"SUMMARY STATISTICS OF SCALED/UNSCALED DATA\")\n",
    "print(\"======= ========== == =============== ====\\n\")\n",
    "print(\"TRAINING DATA:\")\n",
    "print(\"     mean unstandardized:\\n\",   np.round(pd.DataFrame(X_train).describe(),2))\n",
    "print(\"\\n     mean standardized:\\n\",   np.round(pd.DataFrame(X_train_std).describe(),2))\n",
    "\n",
    "\n",
    "print(\"\\nTEST DATA:\")\n",
    "print(\"   mean unstandarized:\\n\",   np.round(pd.DataFrame(X_test).describe().T[['mean','std','50%']].T,2))\n",
    "print(\"\\n   mean standardized ng (wrong!):\\n\", np.round(pd.DataFrame(X_test_std_ng).describe().T[['mean','std','50%']].T,2))\n",
    "print(\"\\n mean standardized (correct):\\n\", np.round(pd.DataFrame(X_test_std).describe().T[['mean','std','50%']].T,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start building our model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model on the standardized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, let's try value of $k=32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=32, p=2, weights='uniform', algorithm='auto')\n",
    "model_knn.fit(X_train_std, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy score: %.3f' % model_knn.score(X_train_std, Y_train))\n",
    "print('Test accuracy score:     %.3f' % model_knn.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a better value for $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "#\n",
    "pipeline = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "#\n",
    "# Create the parameter grid\n",
    "#\n",
    "param_grid = [{\n",
    "    'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 32],\n",
    "    'kneighborsclassifier__p': [1, 2],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}]\n",
    "#\n",
    "# Create a grid search instance\n",
    "#\n",
    "gs = GridSearchCV(pipeline, param_grid = param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  refit=True,\n",
    "                  cv=10,\n",
    "                  verbose=1,\n",
    "                  n_jobs=2)\n",
    "#\n",
    "# Fit the most optimal model\n",
    "#\n",
    "gs.fit(X_train, Y_train)\n",
    "#\n",
    "# Print the best model parameters and scores\n",
    "#\n",
    "print('Best Score: %.3f' % gs.best_score_, '\\nBest Parameters: ', gs.best_params_)\n",
    "#\n",
    "# Print the model score for test data\n",
    "#\n",
    "print('Score: %.3f' % gs.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model with the 'optimal' value of $k = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "model_knn_gs = KNeighborsClassifier(n_neighbors=5, p=2, weights='uniform', algorithm='auto')\n",
    "model_knn_gs.fit(X_train_std, Y_train)\n",
    "\n",
    "print(\"                           k=32         k=5\")\n",
    "print(f'Training accuracy score:   {model_knn.score(X_train_std, Y_train):.3f}        {model_knn_gs.score(X_train_std, Y_train):.3f}')\n",
    "print(f'Test accuracy score:       {model_knn.score(X_test_std, Y_test):.3f} {model_knn_gs.score(X_test_std, Y_test):.3f}')\n",
    "\n",
    "Y_test_hat =  model_knn_gs.predict(X_test_std)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Why did we only use `accuracy_score` rather than `auc` ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize current model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up plot colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "# RGB colors\n",
    "RED      = (1.00, 0.00, 0.00)\n",
    "GREEN    = (0.13, 0.55, 0.13)\n",
    "BLUE     = (0.00, 0.00, 0.93)\n",
    "LTRED    = (1.00, 0.42, 0.60)\n",
    "LTBLUE   = (0.28, 0.77, 1.00)\n",
    "LTGREEN  = (0.29, 0.98, 0.29)\n",
    "\n",
    "n_train = len(Y_train)\n",
    "n_test  = len(Y_test)\n",
    "\n",
    "train_colors = [None] * n_train\n",
    "for i in range(n_train): \n",
    "    if Y_train[i] == 0:\n",
    "        train_colors[i] = LTRED\n",
    "    elif Y_train[i] == 1:\n",
    "        train_colors[i] = LTGREEN        \n",
    "    else:\n",
    "        train_colors[i] = LTBLUE\n",
    "        \n",
    "test_colors  = [None] * n_test\n",
    "for i in range(n_test):\n",
    "    if Y_test_hat[i] == 0:\n",
    "        test_colors[i] = RED\n",
    "    elif Y_test_hat[i] == 1:\n",
    "        test_colors[i] = GREEN        \n",
    "    else:\n",
    "        test_colors[i] = BLUE \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2dKNN(x_train, y_train, x_test, y_test, \n",
    "              nrow, ncol, plot_num, xname=\"x1\", yname =\"x2\", \n",
    "              train_colors=(0,0,0), test_colors = (0,0,0)):\n",
    "    \n",
    "    ax = plt.subplot(nrow, ncol, plot_num)\n",
    "    plt.scatter(x_train, y_train,  s=20, c=train_colors)\n",
    "    plt.scatter(x_test, y_test,  s=70, c=test_colors, marker = \"*\")\n",
    "    plt.xlabel(xname, size = 16)\n",
    "    plt.ylabel(yname, size = 16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.title(xname + \", \" + yname + \" slice for KNN\", size = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               \n",
    "# ------- Set up plot region and parameters    \n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "# ------- row 1\n",
    "\n",
    "v1_id = 0; v2_id = 1; i = 1\n",
    "plot2dKNN(X_train_std[:,v1_id], X_train_std[:,v2_id], \n",
    "          X_test_std[:,v1_id],  X_test_std[:,v2_id],\n",
    "          3, 3, i, \"x1\",  \"x2\", train_colors, test_colors )   \n",
    "\n",
    "x1_id = 0; x2_id = 2; i+=1\n",
    "plot2dKNN(X_train_std[:,v1_id], X_train_std[:,v2_id], \n",
    "          X_test_std[:,v1_id],  X_test_std[:,v2_id],\n",
    "          3, 3, i, \"x1\",  \"x3\", train_colors, test_colors )   \n",
    "\n",
    "x1_id = 0; x2_id = 3; i+=1\n",
    "plot2dKNN(X_train_std[:,v1_id], X_train_std[:,v2_id], \n",
    "          X_test_std[:,v1_id],  X_test_std[:,v2_id],\n",
    "          3, 3, i, \"x1\",  \"x4\", train_colors, test_colors )   \n",
    "\n",
    "# ------- row 2\n",
    "\n",
    "i+=1    # spacer to skip unused plot matrix subplot\n",
    "\n",
    "x1_id = 1; x2_id = 2; i+=1\n",
    "plot2dKNN(X_train_std[:,v1_id], X_train_std[:,v2_id], \n",
    "          X_test_std[:,v1_id],  X_test_std[:,v2_id],\n",
    "          3, 3, i, \"x2\",  \"x3\", train_colors, test_colors )  \n",
    "\n",
    "x1_id = 1; x2_id = 3; i+=1\n",
    "plot2dKNN(X_train_std[:,v1_id], X_train_std[:,v2_id], \n",
    "          X_test_std[:,v1_id],  X_test_std[:,v2_id],\n",
    "          3, 3, i, \"x2\",  \"x4\", train_colors, test_colors )   \n",
    "\n",
    "# ------- row 3\n",
    "\n",
    "i += 1  # spacer to skip unused plot matrix subplot\n",
    "i += 1  # spacer to skip unused plot matrix subplot\n",
    "\n",
    "x1_id = 2; x2_id = 3; i+=1\n",
    "plot2dKNN(X_train_std[:,v1_id], X_train_std[:,v2_id], \n",
    "          X_test_std[:,v1_id],  X_test_std[:,v2_id],\n",
    "          3, 3, i, \"x3\",  \"x4\", train_colors, test_colors )  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FP's Supervised segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
